{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import SGD\n",
    "from torch.autograd import Variable, profiler\n",
    "import numpy as np\n",
    "import torch.functional as F\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.core.display import display, HTML, Image\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"\"\"Me and my uncle went ridin' down\n",
    "To South Colorado, west Texas bound\n",
    "We stopped over in Santa Fe,\n",
    "That day on the pony, just about half way\n",
    "And you know it was the hottest part of the day\n",
    "I took the horses up to the stall\n",
    "Went to the barroom, ordered drinks for all\n",
    "Three days in the saddle, You know my body hurt\n",
    "It being summer, I took off my shirt\n",
    "And I tried to wash off some of that dusty dirt\n",
    "West Texas cowboys, they was all around,\n",
    "Wheat liquor and money, they loaded down,\n",
    "So soon after payday, no one seemed ashamed,\n",
    "You know my uncle, he starts playin' the game,\n",
    "Hey! A hollow jack and the winner take the hand.\n",
    "My uncle starts winning, the cowboys got sore,\n",
    "One of them called him, and then two more,\n",
    "Accused him of cheatin', oh no it couldn't be,\n",
    "I know my uncle he's as honest as me,\n",
    "And I'm as honest as a Denver man can be.\n",
    "One of them cowboys he starsts to draw,\n",
    "And I shot him down Lord, He never saw,\n",
    "Shot me another, Right then he hit the floor,\n",
    "In the confusion, my uncle grabbed the gold,\n",
    "And we hightailed it down to Mexico.\n",
    "Now I love thoe cowboys, I love their gold,\n",
    "Love my uncle, God rest his soul,\n",
    "Taught me good Lord, Taught me all I know,\n",
    "Taught me so well, that I grabbed that gold, and\n",
    "I left his dead ass there by the side of the road\"\"\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Splits corpus into paragraph and sentence and word\n",
    "for paragraph in corpus:\n",
    "    for sentence in paragraph.split('\\n'):\n",
    "        for word in sentence.split():\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build vocabulary\n",
    "words = []\n",
    "for sentence in corpus:\n",
    "    for word in sentence.split():\n",
    "         if word not in words:\n",
    "            words.append(word)\n",
    "        \n",
    "word2idx = {w:idx for (idx, w) in enumerate(words)}\n",
    "idx2word = {idx:w for (idx, w) in enumerate(words)}\n",
    "\n",
    "vocabulary_size = len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## example\n",
    "#word2idx\n",
    "#idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embedding(word):\n",
    "    word_vec_one_hot = np.zeros(vocabulary_size)\n",
    "    word_vec_one_hot[word2idx[word]] = 1\n",
    "    return word_vec_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## example\n",
    "#get_word_embedding('me')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dims = 10\n",
    "window_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator():\n",
    "    for sentence in corpus:\n",
    "        words = sentence.split()\n",
    "        indices = [word2idx[w] for w in words]\n",
    "        for i in range(len(indices)):\n",
    "            # center word, context\n",
    "            # i is center word index\n",
    "            for w in range(-window_size, window_size + 1):\n",
    "                context_idx = i + w\n",
    "                if context_idx < 0 or context_idx >= len(indices) or i == context_idx:\n",
    "                    continue\n",
    "                center_vec_one_hot = np.zeros(vocabulary_size)\n",
    "                center_vec_one_hot[indices[i]] = 1\n",
    "                \n",
    "                context_idx = indices[context_idx]\n",
    "                yield center_vec_one_hot, context_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network definition\n",
    "W1 = Variable(torch.randn(embedding_dims, vocabulary_size).float(), requires_grad=True)\n",
    "W2 = Variable(torch.randn(vocabulary_size, embedding_dims).float(), requires_grad=True)\n",
    "\n",
    "\n",
    "for epo in range(501):\n",
    "    avg_loss = 0\n",
    "    samples = 0\n",
    "    for data, target in train_generator():\n",
    "        x = Variable(torch.from_numpy(data)).float()\n",
    "        y_true = Variable(torch.from_numpy(np.array([target])).long())\n",
    "        samples += len(y_true)\n",
    "        \n",
    "        a1 = torch.matmul(W1, x)\n",
    "        a2 = torch.matmul(W2, a1)\n",
    "\n",
    "        log_softmax = F.log_softmax(a2, dim=0)\n",
    "\n",
    "        network_pred_dist = F.softmax(log_softmax, dim=0)\n",
    "        loss = F.nll_loss(log_softmax.view(1,-1), y_true)\n",
    "        avg_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        W1.data -= 0.01 * W1.grad.data\n",
    "        W2.data -= 0.01 * W2.grad.data\n",
    "\n",
    "        W1.grad.data.zero_()\n",
    "        W2.grad.data.zero_()\n",
    "        \n",
    "    if epo % 50 == 0:\n",
    "        print(avg_loss / samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from scikitplot.decomposition import plot_pca_2d_projection\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(W1.data.numpy().T)\n",
    "proj = pca.transform(W1.data.numpy().T)\n",
    "ax = plot_pca_2d_projection(pca, W1.data.numpy().T, np.array(words), feature_labels=words, figsize=(18,18), text_fontsize=12)\n",
    "# ax.legend(None)\n",
    "for i, txt in enumerate(words):\n",
    "    ax.annotate(txt, (proj[i,0], proj[i,1]), size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vector_v(word):\n",
    "    return W1[:, word2idx[word]].data.numpy()\n",
    "\n",
    "def get_word_vector_u(word):\n",
    "    return W2[word2idx[word],:].data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# me to we is like uncle to ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me = 1 * get_word_vector_v('me') + 1 * get_word_vector_u('me')\n",
    "uncle = 1 * get_word_vector_v('uncle') + 1 * get_word_vector_u('uncle') \n",
    "we = 1 * get_word_vector_v('we') + 1 * get_word_vector_u('we') \n",
    "\n",
    "yyy = we - me + uncle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "distances = [(v, cosine(yyy, 1 * get_word_vector_u(v) + 1 * get_word_vector_v(v))) for v in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poland to Warsaw is like Germany to Berlin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In what context Paris appears?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_to_predict = get_word_vector_v('as')\n",
    "hidden = Variable(torch.from_numpy(context_to_predict)).float()\n",
    "a = torch.matmul(W2, hidden)\n",
    "probs = F.softmax(a, dim=0).data.numpy()\n",
    "for context, prob in zip(words, probs):\n",
    "    print(f'{context}: {prob:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = [pd.Series([*i]) for i in zip(words, probs)]\n",
    "prob_of_contex_word = pd.concat(series, axis=1).T\n",
    "prob_of_contex_word.sort_values(1, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In context of \"France\" and \"is\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
